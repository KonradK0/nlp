{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of lab-6-word2vec.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/gmum/natural-language-processing-classes/blob/master/lab-6-word2vec/notebook.ipynb","timestamp":1543485371507}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"zfeZuPw4dW5j","colab_type":"text"},"cell_type":"markdown","source":["# Lab 6 - word-2-vec with pytorch and gensim\n","\n"," \"A word is characterized by the company it keeps\" - Firth (1957)\n"," "]},{"metadata":{"id":"Au1y1zTzg5L1","colab_type":"text"},"cell_type":"markdown","source":["# Exercise 1 (2pt)\n","\n","\n","- Train word2vec skip-gram model on sentence \"the quick brown fox jumps over the lazy dog\". Assume context window = 2, embedding_dim = 5. No preprocessing apart from tokenization.\n","- Compute model output probabilities for words \"lazy\" and \"dog\". If you have trained the model correctly, the output probabilities for word \"lazy\" should be higher for words \"over\", \"the\", \"dog\" (close to 1/3 each) and lower for other words (close to 0 each). For word \"dog\", the output probabilities should be higher for words, \"the\", \"dog\" (close to 1/2 each) and lower for other words (close to 0 each). \n","- Compute dot product between the vector of word \"dog\" and the vector of word \"lazy\" (could be representation of center vector and representation of context vector) and between \"dog\" and \"brown\". Which one is higher? Why?\n","\n","\n","You can use this tutorial https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb\n","\n","Use pytorch (or tensorflow)."]},{"metadata":{"id":"VOKM7MX0g779","colab_type":"code","outputId":"84850349-4835-4556-989c-8b40dc6f9769","executionInfo":{"status":"ok","timestamp":1543504347202,"user_tz":-60,"elapsed":33301,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","torch.manual_seed(1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x57a44000 @  0x7f1fba1282a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f6e54fbd710>"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"t-Fx_0DGjZDX","colab_type":"code","colab":{}},"cell_type":"code","source":["sentence = \"the quick brown fox jumps over the lazy dog\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"06o7-BSrpSoO","colab_type":"code","outputId":"1d452c77-df88-4724-ec65-93a55847855f","executionInfo":{"status":"ok","timestamp":1543504924238,"user_tz":-60,"elapsed":1019,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"cell_type":"code","source":["import numpy as np\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","vocab = (word_tokenize(sentence))\n","word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n","idx2word = {idx: w for (idx, w) in enumerate(vocab)}\n","\n","WINDOW_SIZE = 2\n","VOCAB_SIZE = len(vocab)\n","EMBEDDING_DIMS = 5\n","EPOCHS = 35\n","idx_pairs = []\n","indices = [word2idx[word] for word in vocab]\n","# for each word, treated as center word\n","for center_word_pos in range(len(indices)):\n","    # for each window position\n","    for w in range(-WINDOW_SIZE, WINDOW_SIZE + 1):\n","        context_word_pos = center_word_pos + w\n","        # make sure not jump out sentence\n","        if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n","            continue\n","        context_word_idx = indices[context_word_pos]\n","        idx_pairs.append((indices[center_word_pos], context_word_idx))\n","\n","idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array\n","\n","\n","class Network(nn.Module):\n","  def __init__(self, vocab_size, embedding_dims):\n","    super(Network, self).__init__()\n","    self.linear = nn.Linear(vocab_size, embedding_dims)\n","    self.inner = nn.Linear(embedding_dims, vocab_size)\n","    \n","  def forward(self, input_vec):\n","    return F.log_softmax(\n","        (self.inner(\n","            self.linear(input_vec)\n","            )\n","        ), dim=0\n","    )\n","\n","\n","def get_input_one_hot(word_idx):\n","    x = torch.zeros(VOCAB_SIZE).float()\n","    x[word_idx] = 1.0\n","    return x\n","  \n","model = Network(VOCAB_SIZE, EMBEDDING_DIMS)\n","loss_function = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","for epoch in range(EPOCHS):\n","  loss_val = 0\n","  for data, target in idx_pairs:\n","    model.zero_grad()\n","    y_true = torch.autograd.Variable(torch.from_numpy(np.array([target])).long())\n","    x = get_input_one_hot(data).float()\n","    logits = model(x)\n","    loss = loss_function(logits.view(1,-1), y_true)\n","    loss_val += loss.data.item()\n","    loss.backward()\n","    optimizer.step()\n","  with torch.no_grad():\n","    if epoch % 5 == 0:\n","      print(f'Loss at epoch {epoch}: {loss_val/len(idx_pairs)}')\n","with torch.no_grad():\n","  lazy = get_input_one_hot(word2idx['lazy'])\n","  probs = torch.exp(model(lazy))\n","  print('\\n Probs for word \\'lazy\\'')\n","  for word, prob in zip(vocab,probs.tolist()):\n","    print('\\t{} : {} '.format(word, format(prob, '.3f')))\n","  print('Sum = {}'.format(format(probs.sum(), '.1f')))\n","  print('\\n Probs for word \\'dog\\'')\n","  dog = get_input_one_hot(word2idx['dog'])\n","  probs = torch.exp(model(dog))\n","  for word, prob in zip(vocab,probs.tolist()):\n","    print('\\t{} : {} '.format(word, format(prob, '.3f')))\n","  print('Sum = {}'.format(format(probs.sum(), '.1f')))\n","  \n","  brown = get_input_one_hot(word2idx['brown'])\n","  print\n","  print('dot(\\'dog\\', \\'lazy\\') =  {}'.format(torch.dot(torch.exp(model(dog)), torch.exp(model(lazy)))))\n","  print('dot(\\'dog\\', \\'brown\\') =  {}'.format(torch.dot(torch.exp(model(dog)), torch.exp(model(brown)))))\n","  "],"execution_count":11,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Loss at epoch 0: 2.2149279634157817\n","Loss at epoch 5: 2.053186905384064\n","Loss at epoch 10: 1.935728371143341\n","Loss at epoch 15: 1.82925044298172\n","Loss at epoch 20: 1.7955500602722168\n","Loss at epoch 25: 1.7913446108500162\n","Loss at epoch 30: 1.7913328210512798\n","\n"," Probs for word 'lazy'\n","\tthe : 0.009 \n","\tquick : 0.012 \n","\tbrown : 0.052 \n","\tfox : 0.018 \n","\tjumps : 0.004 \n","\tover : 0.210 \n","\tthe : 0.272 \n","\tlazy : 0.034 \n","\tdog : 0.389 \n","Sum = 1.0\n","\n"," Probs for word 'dog'\n","\tthe : 0.002 \n","\tquick : 0.011 \n","\tbrown : 0.009 \n","\tfox : 0.036 \n","\tjumps : 0.023 \n","\tover : 0.007 \n","\tthe : 0.317 \n","\tlazy : 0.552 \n","\tdog : 0.044 \n","Sum = 1.0\n","dot('dog', 'lazy') =  0.12468066811561584\n","dot('dog', 'brown') =  0.09756961464881897\n"],"name":"stdout"}]},{"metadata":{"id":"HJ9woWyKCv7t","colab_type":"text"},"cell_type":"markdown","source":["   Dot('dog', 'lazy') is bigger than dot('dog', 'brown') because they are more similar to each other ('the' is the context for both 'lazy' and 'dog', wheareas 'dog' and 'brown' contexts are disjoint)"]},{"metadata":{"id":"CRnIu7hAB6sF","colab_type":"text"},"cell_type":"markdown","source":["If our vocabulary is bigger, the word2vec model needs a LOT of data to obtain reasonable results. With this amount of data, the code needs to be optimized very well. Writing such code will be more suitable for a project instead of a simple exercise, therefore in the next exercise we will use [gensim](https://radimrehurek.com/gensim/), a library made for efficient training of word vectors.\n","\n","# * Exercise 2 (2pt)\n","\n","- Use [gensim](https://radimrehurek.com/gensim/) to train a word2vec model on [OpinRank](http://kavita-ganesan.com/entity-ranking-data/). You can follow this [tutorial](https://medium.freecodecamp.org/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3), but make sure you have used negative sampling.\n","- Find 10 similar words to word \"dirty\" and \"canada\"\n","- Check if similarity between \"dirty\" and \"dusty\" is bigger than between \"dirty\" and \"clean\""]},{"metadata":{"id":"m-WqD1xKDE0p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":714},"outputId":"268156c5-06b5-49f1-c69c-7087b537b806","executionInfo":{"status":"ok","timestamp":1543504087905,"user_tz":-60,"elapsed":15146,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}}},"cell_type":"code","source":["!pip install --upgrade gensim\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n","\u001b[K    100% |████████████████████████████████| 23.6MB 1.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n","Collecting smart-open>=1.2.1 (from gensim)\n","  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n","Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n","\u001b[K    100% |████████████████████████████████| 1.4MB 13.2MB/s \n","\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n","  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n","Collecting boto3 (from smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/25/63011a0c2940bdefa77eb45a44e3de0f8599859edf4ca0c321ee0fb757e2/boto3-1.9.55-py2.py3-none-any.whl (128kB)\n","\u001b[K    100% |████████████████████████████████| 133kB 19.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n","Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 15.9MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n","  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n","Collecting botocore<1.13.0,>=1.12.55 (from boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/be/da181a69e355ec61224de70d2afd306d723834adf2af98ee163975cf8357/botocore-1.12.55-py2.py3-none-any.whl (5.1MB)\n","\u001b[K    100% |████████████████████████████████| 5.1MB 7.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.55->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n","Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.55->boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n","\u001b[K    100% |████████████████████████████████| 552kB 24.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n","  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n","  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n","Successfully built smart-open bz2file\n","Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n","Successfully installed boto-2.49.0 boto3-1.9.55 botocore-1.12.55 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"],"name":"stdout"}]},{"metadata":{"id":"reJdvmlFAvLg","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":55},"outputId":"e70356dc-d71f-41f9-d0c5-f8fab6e9d50d"},"cell_type":"code","source":["# imports needed and logging\n","import gzip\n","import gensim \n","from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-bcaf3c11-2901-4de6-bcc5-df8602d7f98e\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-bcaf3c11-2901-4de6-bcc5-df8602d7f98e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving OpinRankDatasetWithJudgments.zip to OpinRankDatasetWithJudgments.zip\n"],"name":"stdout"}]},{"metadata":{"id":"YO3h77sfGqQs","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_input(input_file):\n","    \"\"\"This method reads the input file which is in gzip format\"\"\"\n","\n","    print(\"reading file {0}...this may take a while\".format(input_file))\n","    with gzip.open(input_file, 'rb') as f:\n","        for i, line in enumerate(f):\n","\n","            if (i % 10000 == 0):\n","                print(\"read {0} reviews\".format(i))\n","            # do some pre-processing and return list of words for each review\n","            # text\n","            yield gensim.utils.simple_preprocess(line)"],"execution_count":0,"outputs":[]}]}