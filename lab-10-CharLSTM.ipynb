{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CharLSTM.ipynb","version":"0.3.2","provenance":[{"file_id":"1ihgf3lKmLZywYklYyujYiMukeW55ZAYn","timestamp":1554975229201}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"AXoRJjuM2-fX","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import sys\n","import math\n","import time\n","import itertools\n","\n","import tensorflow as tf\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tensorflow import keras\n","from sklearn.preprocessing import OneHotEncoder\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E2mxrCHGXQyx","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ln7sg112XQ9c","colab_type":"text"},"cell_type":"markdown","source":["# Recurrent Neural Networks\n","\n","[Karpathy's blog about RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"]},{"metadata":{"id":"R21p4AwhXvfB","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","    'If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.'"]},{"metadata":{"id":"0opiBUGLOXlh","colab_type":"text"},"cell_type":"markdown","source":["Sequences. Depending on your background you might be wondering: What makes Recurrent Networks so special? A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model). The core reason that recurrent nets are more exciting is that they allow us to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both."]},{"metadata":{"id":"zFzU6EieXpUR","colab_type":"text"},"cell_type":"markdown","source":["![](http://karpathy.github.io/assets/rnn/diags.jpeg)\n","\n","Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN's state. From left to right: \n","\n","1. Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). \n","\n","2. Sequence output (e.g. image captioning takes an image and outputs a sentence of words). \n","\n","3. Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). \n","\n","4. Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French).\n","\n","5. Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like."]},{"metadata":{"id":"IVlv6p8OYml8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0bLe8FITX7S9","colab_type":"text"},"cell_type":"markdown","source":["## RNN\n","\n","![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n","\n","![](https://image.slidesharecdn.com/rnn-lstm-161106132927/95/understanding-rnn-and-lstm-4-638.jpg?cb=1478439617)\n"]},{"metadata":{"id":"CmuzjCN9YnQU","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"y9vqvfb7Yd77","colab_type":"text"},"cell_type":"markdown","source":["## The Problem of Long-Term Dependencies\n","\n","![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)\n","\n","![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png)"]},{"metadata":{"id":"DXLul8XgYn8_","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0zaSfKBtYKV6","colab_type":"text"},"cell_type":"markdown","source":["## LSTM\n","\n","[Colah's blog about LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n","\n","![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n","\n","![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png)"]},{"metadata":{"id":"RxB6cCU3ZAji","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"stgYnrxEZArj","colab_type":"text"},"cell_type":"markdown","source":["## Language models\n","\n","![](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/rnnlm.png)\n","\n","![](http://karpathy.github.io/assets/rnn/charseq.jpeg)\n","\n","![](https://i.redd.it/cw04e9546gv11.png)"]},{"metadata":{"id":"xcI2Ow7z2-h9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0rJ_JEMUZ6bV","colab_type":"text"},"cell_type":"markdown","source":["# Train character level RNN for language modelling"]},{"metadata":{"id":"w9-7eypD2-ul","colab_type":"text"},"cell_type":"markdown","source":["## Load corpora\n","\n","Upload text file from your drive"]},{"metadata":{"id":"ZnQ6gaXM2Qkf","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XYet8joa2wnp","colab_type":"code","outputId":"3552c7d9-5469-4849-acb5-f97def79b0b9","executionInfo":{"status":"ok","timestamp":1554970319450,"user_tz":-120,"elapsed":24513,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"cell_type":"code","source":["uploaded = files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-1c2ea270-6e56-4fec-b00e-63bae8c0c4d9\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-1c2ea270-6e56-4fec-b00e-63bae8c0c4d9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving sheakspeare.txt to sheakspeare.txt\n"],"name":"stdout"}]},{"metadata":{"id":"vakZ99Wf2zLY","colab_type":"code","colab":{}},"cell_type":"code","source":["data = str(list(uploaded.values())[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rskbQq-a3BoT","colab_type":"text"},"cell_type":"markdown","source":["## Prepare dataset"]},{"metadata":{"id":"lndmged3bWdw","colab_type":"text"},"cell_type":"markdown","source":["Calculate vocabulary size. Create char2index and index2char dictionaries, that could help us in text vectorizing"]},{"metadata":{"id":"6teZDS3K28KZ","colab_type":"code","outputId":"99ada54c-e117-476b-f7e6-ba111046a0b8","executionInfo":{"status":"ok","timestamp":1554974187398,"user_tz":-120,"elapsed":858,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["chars = list(set(data))\n","data_size, vocab_size = len(data), len(chars)\n","print('data has %d characters, %d unique.' % (data_size, vocab_size))\n","\n","char_to_ix = { ch:i for i,ch in enumerate(chars) }\n","ix_to_char = { i:ch for i,ch in enumerate(chars) }"],"execution_count":0,"outputs":[{"output_type":"stream","text":["data has 1235397 characters, 66 unique.\n"],"name":"stdout"}]},{"metadata":{"id":"E7ADrFEab2SZ","colab_type":"text"},"cell_type":"markdown","source":["Prepare text x and y datasets"]},{"metadata":{"id":"P0VZP6MP28Mf","colab_type":"code","outputId":"9be89bf9-53d5-4a83-edbd-9aafcdf987fc","executionInfo":{"status":"ok","timestamp":1554974188849,"user_tz":-120,"elapsed":1945,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["max_len = 20\n","step = 3\n","\n","sentences = []\n","next_chars = []\n","for i in range(0, len(data) - max_len, step):\n","    sentences.append(data[i: i + max_len])\n","    next_chars.append(data[i + max_len])\n","    \n","print(\"total # of sentences: \", len(sentences))    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["total # of sentences:  411793\n"],"name":"stdout"}]},{"metadata":{"id":"0SeJxVjucBUL","colab_type":"text"},"cell_type":"markdown","source":["Translate string datasets into number vectors"]},{"metadata":{"id":"uFyWM42cDIwK","colab_type":"code","outputId":"36e27622-303a-4420-c63d-2b6a20bf7d5b","executionInfo":{"status":"ok","timestamp":1554974194005,"user_tz":-120,"elapsed":4667,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x = np.zeros((len(sentences), max_len), dtype=np.int)\n","y = np.zeros((len(sentences)), dtype=np.int)\n","\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t] = char_to_ix[char]\n","        \n","    y[i] = char_to_ix[next_chars[i]]\n","    \n","x.shape, y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((411793, 20), (411793,))"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"iuX-XQro5MvH","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ctXdMbRX8PLS","colab_type":"text"},"cell_type":"markdown","source":["## Define model"]},{"metadata":{"id":"0niLOfSeeS9j","colab_type":"text"},"cell_type":"markdown","source":["Define the character level LSTM model for text generation that consists of:\n","\n","1.   (Optional) Embedding layer [keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) for training the word embeddings. You should pass the propper input dim to the layer and specify the embedding dim. **Note** that because we use the RNN model, you don't need to specify the input sequence length.\n","\n","2.   Some LSTM layers [keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) with specified number of hidden units.  **Note** that middle LSTM layers should return full sequences (you can specify this with parameter **return_sequences**).\n","\n","3.   Together with LSTM layers, you can also use the dropout layers [keras.layers.Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout), to regularize the network.\n","\n","4.   Final dense layer for making the classification [keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), with specified number of output units and activation function."]},{"metadata":{"id":"VOdCCGE9cuWZ","colab_type":"text"},"cell_type":"markdown","source":["**Define model hyperparameters**"]},{"metadata":{"id":"gACUhZX89STd","colab_type":"code","colab":{}},"cell_type":"code","source":["dropout_rate = 0.3\n","hidden_dim = 100\n","\n","dropout = keras.layers.Dropout(rate=dropout_rate)\n","\n","input_dim = vocab_size\n","lstm_1_out_dim = 256\n","output_dim = vocab_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eTRHsX6RcyLZ","colab_type":"text"},"cell_type":"markdown","source":["**Define model as keras sequential**"]},{"metadata":{"id":"ZErwu9Tvc5hI","colab_type":"code","colab":{}},"cell_type":"code","source":["model = keras.models.Sequential()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vC3TVHZgc16R","colab_type":"text"},"cell_type":"markdown","source":["**Define the embedding layer**\n","\n","You could define the **optional** embedding layer"]},{"metadata":{"id":"YC3S0Y_Kc1P-","colab_type":"code","colab":{}},"cell_type":"code","source":["embedding_layer = keras.layers.Embedding(input_dim,\n","                                         hidden_dim)\n","\n","model.add(embedding_layer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tQmwPFIvdC1I","colab_type":"text"},"cell_type":"markdown","source":["**Define LSTM layers**\n","\n","You could define as many LSTM layers, as you want. Remember that middle LSTM layers should return full sequences, not one word (you can specify this with parameter *return_sequences*). You could also define dropout after LSTM layers."]},{"metadata":{"id":"Rl_Q47SUdei0","colab_type":"code","colab":{}},"cell_type":"code","source":["lstm1 = keras.layers.CuDNNLSTM(lstm_1_out_dim, return_sequences=True)\n","lstm2 = keras.layers.CuDNNLSTM(output_dim, return_sequences=False)\n","model.add(lstm1)\n","model.add(dropout)\n","model.add(lstm2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"do60Rn_fdn5v","colab_type":"text"},"cell_type":"markdown","source":["**Define dense classification layer**"]},{"metadata":{"id":"aultpz_N5Mxs","colab_type":"code","colab":{}},"cell_type":"code","source":["out = keras.layers.Dense(output_dim, activation='softmax')\n","model.add(out)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ij2SvklHc1TG","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2Ir96n75d1WR","colab_type":"text"},"cell_type":"markdown","source":["**Compile the model**"]},{"metadata":{"id":"gacrPMqh_N4u","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='sparse_categorical_crossentropy', \n","              optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bTHfUgI5dy4s","colab_type":"text"},"cell_type":"markdown","source":["**Check the model summary**"]},{"metadata":{"id":"JwQtJhYG8Qt9","colab_type":"code","outputId":"a31bba40-261c-4c55-9158-7ea0cf029f96","executionInfo":{"status":"ok","timestamp":1554974760429,"user_tz":-120,"elapsed":1968,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, None, 100)         6600      \n","_________________________________________________________________\n","cu_dnnlstm_10 (CuDNNLSTM)    (None, None, 256)         366592    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, None, 256)         0         \n","_________________________________________________________________\n","cu_dnnlstm_11 (CuDNNLSTM)    (None, 66)                85536     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 66)                4422      \n","=================================================================\n","Total params: 463,150\n","Trainable params: 463,150\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"UO0EyyCxaEMd","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0S3U-ac5B1mM","colab_type":"text"},"cell_type":"markdown","source":["## Define sampling function"]},{"metadata":{"id":"9L6Bo3ZOgIBD","colab_type":"text"},"cell_type":"markdown","source":["Define the function that takes the model and generates the string from characters sampled from model probabilities."]},{"metadata":{"id":"R7oxVKgoB356","colab_type":"code","colab":{}},"cell_type":"code","source":["def sample_string(model, seq_len, input_sequence=None):\n","    if input_sequence is None:\n","        generated_sequence = ix_to_char[x[np.random.choice(len(x)),0]]\n","    else:\n","        generated_sequence = input_sequence\n","    \n","    for _ in range(seq_len):\n","        seq_vector = np.array([[char_to_ix[c] for c in generated_sequence]])\n","#         print(seq_vector)\n","        word_proba = model.predict_proba(seq_vector)\n","#         print(vocab_size)\n","#         print(word_proba.shape)\n","#         print(word_proba.flatten().shape)\n","        predicted_word = ix_to_char[np.random.choice(vocab_size, p=word_proba.flatten())]\n","        generated_sequence += predicted_word\n","\n","    return generated_sequence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yTo3KMEkaFbN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"yzfXZe8dB4Af","colab_type":"text"},"cell_type":"markdown","source":["## Train model"]},{"metadata":{"id":"mOY8lJiI8QxM","colab_type":"code","outputId":"685da0c5-ed4e-415c-f177-7b55aaec10cf","executionInfo":{"status":"error","timestamp":1554975226023,"user_tz":-120,"elapsed":454514,"user":{"displayName":"Konrad Korus","photoUrl":"","userId":"14275814191289948503"}},"colab":{"base_uri":"https://localhost:8080/","height":1067}},"cell_type":"code","source":["sample_len = 100\n","\n","generated_string = sample_string(model, sample_len)\n","print(\"Sample string before training: '%s'\" % generated_string)\n","\n","for epoch in range(100):\n","    model.fit(x, y, batch_size=256, epochs=1)\n","    generated_string = sample_string(model, sample_len)\n","    print(\"Sample string after epoch %d: '%s'\" % (epoch, generated_string))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sample string before training: ' cdk KbJsHLy bqXdV\"IaLrUDFMLYoYWJ\\\"l?SPoAKWh:ImoTJ U&QjX'-uCYglZlaLaQ\\U';.s$B$TZ,tLlpdZkZBu\"BI'ZhHe, '\n","411793/411793 [==============================] - 46s 111us/sample - loss: 2.4405 - acc: 0.3350\n","Sample string after epoch 0: 'evi; su fome kaam, hit aroralsl thas go sid sveor heunson'r\\r\\nWraiuide hif me tuechyret' rum e wo sr'\n","411793/411793 [==============================] - 45s 108us/sample - loss: 2.0199 - acc: 0.4211\n","Sample string after epoch 1: ' D:ivind have hich aw elker.\\r\\n\\r\\nPhanord'clet mendred now the, he gourlawe my mens tremy in math d'\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.8919 - acc: 0.4525\n","Sample string after epoch 2: ' nLoals syors lom;\\r\\nRoorse: and of the enll,\\r\\nO ctent tipe, and to bust ty shalkengy jiam onout, '\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.7891 - acc: 0.4783\n","Sample string after epoch 3: '''VA OIN:\\r\\nOl a youss, ar-o shore aurst.\\r\\nThe tive yame unme Conturves,\\r\\nAnd hard favet prierd '\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.7174 - acc: 0.4961\n","Sample string after epoch 4: 'e'lle bamas unqueen at then,\\r\\nAnd cition you his af that tufing, last:\\r\\nIn crest must death sheer'\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.6584 - acc: 0.5111\n","Sample string after epoch 5: 'thaif-ank you, hear his hither the can preace have\\r\\nMy reneaves Korger.\\r\\nGuve men, no redues and '\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.6134 - acc: 0.5236\n","Sample string after epoch 6: 'o'sers\\r\\nWitchen I'll and well?\\r\\n\\r\\nQUGET:\\r\\nGhasy am I have of ligh\\r\\nThe ongo.'\\r\\n\\r\\nPLOSDA'\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.5751 - acc: 0.5341\n","Sample string after epoch 7: 'nnengh,\\r\\nWherese here yours, shish my spower panes:\\r\\nYou unthat will thee I know thou thince I\\r\\'\n","411793/411793 [==============================] - 45s 108us/sample - loss: 1.5451 - acc: 0.5418\n","Sample string after epoch 8: 'nhich bose fault, Ixeet you have I.\\r\\n\\r\\nADIO:\\r\\nLuy, in the jaciant and say, but thou say and you'\n","393728/411793 [===========================>..] - ETA: 1s - loss: 1.5169 - acc: 0.5491"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-d080805be384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgenerated_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample string after epoch %d: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"c7-qVMOJI8uT","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"nyPKBNoFVvIE","colab_type":"text"},"cell_type":"markdown","source":["# Images sources\n","\n","Images and code fragments used in this notebook comes from the following web pages and papers:\n","\n","1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n","2. http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","3. https://pt.slideshare.net/ssuser6c624f/understanding-rnn-and-lstm\n","4. [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)\n","5. https://github.com/JY-H/character-level-rnn/blob/master/src/character_level.py"]},{"metadata":{"id":"J9qyFHWwXH7w","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}